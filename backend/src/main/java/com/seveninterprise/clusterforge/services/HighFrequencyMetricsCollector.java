package com.seveninterprise.clusterforge.services;

import com.seveninterprise.clusterforge.model.Cluster;
import com.seveninterprise.clusterforge.model.ClusterHealthMetrics;
import com.seveninterprise.clusterforge.repository.ClusterRepository;
import com.seveninterprise.clusterforge.repositories.ClusterHealthMetricsRepository;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.scheduling.annotation.Scheduled;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;

import java.util.List;
import java.util.Map;
import java.util.concurrent.CompletableFuture;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.stream.Collectors;

/**
 * Servi√ßo dedicado para coletar m√©tricas em alta frequ√™ncia (20 pacotes/segundo)
 * 
 * Este servi√ßo coleta m√©tricas do Docker de forma ass√≠ncrona e otimizada,
 * permitindo atualiza√ß√µes em tempo real sem bloquear o sistema principal.
 */
@Service
public class HighFrequencyMetricsCollector {
    
    private final ClusterRepository clusterRepository;
    private final ClusterHealthService clusterHealthService;
    private final MetricsWebSocketService metricsWebSocketService;
    private final ClusterHealthMetricsRepository metricsRepository;
    private final DockerService dockerService;
    
    // Executor para coletar m√©tricas em paralelo
    private final ExecutorService metricsCollectorExecutor;
    
    // Cache de √∫ltima coleta por cluster (para evitar coletas muito frequentes do mesmo cluster)
    private final Map<Long, Long> lastCollectionTime = new ConcurrentHashMap<>();
    // Intervalo m√≠nimo entre coletas do mesmo cluster (ajustado para 200ms para evitar sobrecarga)
    private static final long MIN_COLLECTION_INTERVAL_MS = 200; // M√≠nimo de 200ms entre coletas do mesmo cluster
    
    // Buffer de m√©tricas para salvar no banco a cada 10 segundos
    // Armazena a √∫ltima m√©trica coletada de cada cluster
    private final Map<Long, ClusterHealthMetrics> metricsBuffer = new ConcurrentHashMap<>();
    
    // Cache de clusters ativos (atualizado a cada 5 segundos para reduzir queries)
    private volatile List<Cluster> cachedRunningClusters = new java.util.ArrayList<>();
    private volatile long lastClusterCacheUpdate = 0;
    private static final long CLUSTER_CACHE_TTL_MS = 5000; // Cache v√°lido por 5 segundos
    private volatile boolean isUpdatingClusterCache = false; // Lock para evitar m√∫ltiplas atualiza√ß√µes simult√¢neas
    
    @Autowired
    public HighFrequencyMetricsCollector(
            ClusterRepository clusterRepository,
            ClusterHealthService clusterHealthService,
            MetricsWebSocketService metricsWebSocketService,
            ClusterHealthMetricsRepository metricsRepository,
            DockerService dockerService) {
        this.clusterRepository = clusterRepository;
        this.clusterHealthService = clusterHealthService;
        this.metricsWebSocketService = metricsWebSocketService;
        this.metricsRepository = metricsRepository;
        this.dockerService = dockerService;
        
        // Thread pool otimizado para coleta r√°pida de m√©tricas
        // Usa n√∫mero de cores dispon√≠veis para paralelismo
        int threadPoolSize = Math.max(4, Runtime.getRuntime().availableProcessors());
        this.metricsCollectorExecutor = Executors.newFixedThreadPool(threadPoolSize);
    }
    
    /**
     * Scheduler para coletar m√©tricas em alta frequ√™ncia (a cada 100ms = 10x/segundo)
     * Coleta apenas m√©tricas de recursos (CPU, RAM, Disk, Network) de forma r√°pida
     * sem fazer health checks completos.
     * 
     * Nota: 100ms √© um bom equil√≠brio entre frequ√™ncia e performance.
     * O WebSocket pode enviar at√© 20x/segundo, mas coletar do Docker a cada 50ms
     * pode ser muito pesado. 100ms (10x/segundo) √© mais realista.
     */
    @Scheduled(fixedRate = 100) // 100ms = 10 vezes por segundo (mais realista para coleta do Docker)
    public void collectMetricsHighFrequency() {
        try {
            // Usar cache de clusters para evitar queries a cada 100ms
            List<Cluster> runningClusters = getCachedRunningClusters();
            
            // Log apenas a cada 5 segundos para n√£o poluir logs
            long now = System.currentTimeMillis();
            boolean shouldLog = (now - lastClusterCacheUpdate) < 100; // Log apenas logo ap√≥s atualiza√ß√£o do cache
            
            if (runningClusters.isEmpty()) {
                if (shouldLog) {
                    System.out.println("‚ö†Ô∏è Nenhum cluster rodando encontrado para coletar m√©tricas");
                }
                return;
            }
            
            if (shouldLog && runningClusters.size() > 0) {
                System.out.println("üìä Coletando m√©tricas para " + runningClusters.size() + " cluster(s) rodando");
            }
            
            // Coletar m√©tricas de todos os clusters em paralelo
            // N√£o aguardar todas as coletas - deixar rodar em background
            // Isso permite que o scheduler continue rodando a cada 100ms
            runningClusters.forEach(cluster -> {
                CompletableFuture.runAsync(() -> {
                    try {
                        collectMetricsForCluster(cluster);
                    } catch (Exception e) {
                        // N√£o logar erros para n√£o poluir logs em alta frequ√™ncia
                        // Apenas em modo debug
                        if ("true".equalsIgnoreCase(System.getenv("DEBUG")) || 
                            "true".equalsIgnoreCase(System.getProperty("debug"))) {
                            System.err.println("Erro ao coletar m√©tricas para cluster " + cluster.getId() + ": " + e.getMessage());
                        }
                    }
                }, metricsCollectorExecutor);
            });
            
        } catch (Exception e) {
            // N√£o quebrar o scheduler se houver erro
            if ("true".equalsIgnoreCase(System.getenv("DEBUG")) || 
                "true".equalsIgnoreCase(System.getProperty("debug"))) {
                System.err.println("Erro no scheduler de coleta de m√©tricas: " + e.getMessage());
            }
        }
    }
    
    /**
     * Coleta m√©tricas para um cluster espec√≠fico diretamente do Docker
     * e envia via WebSocket sem passar pelo banco de dados
     */
    private void collectMetricsForCluster(Cluster cluster) {
        // Throttling por cluster: evitar coletas muito frequentes do mesmo cluster
        long now = System.currentTimeMillis();
        Long lastCollection = lastCollectionTime.get(cluster.getId());
        if (lastCollection != null && (now - lastCollection) < MIN_COLLECTION_INTERVAL_MS) {
            return; // Ainda n√£o passou o intervalo m√≠nimo
        }
        
        lastCollectionTime.put(cluster.getId(), now);
        
        try {
            // Coletar m√©tricas diretamente do Docker
            // Pular m√©tricas adicionais (docker inspect) e usar quiet mode para n√£o poluir logs
            ClusterHealthMetrics metrics = clusterHealthService.collectResourceMetrics(cluster, true, true);
            
            if (metrics != null) {
                // Enviar diretamente via WebSocket (sem salvar no banco imediatamente)
                metricsWebSocketService.sendMetricsDirectly(cluster, metrics);
                
                // Armazenar no buffer para salvar no banco a cada 10 segundos
                metricsBuffer.put(cluster.getId(), metrics);
            }
        } catch (Exception e) {
            // Ignorar erros silenciosamente para n√£o quebrar o scheduler
            // Em modo debug, logar
            if ("true".equalsIgnoreCase(System.getenv("DEBUG")) || 
                "true".equalsIgnoreCase(System.getProperty("debug"))) {
                System.err.println("Erro ao coletar m√©tricas para cluster " + cluster.getId() + ": " + e.getMessage());
            }
        }
    }
    
    /**
     * Scheduler para salvar m√©tricas no banco a cada 10 segundos
     * Salva apenas a √∫ltima m√©trica coletada de cada cluster (a mais recente)
     */
    @Scheduled(fixedRate = 10000) // 10 segundos
    @Transactional(timeout = 15) // Timeout de 15 segundos para batch save
    public void saveMetricsToDatabase() {
        try {
            if (metricsBuffer.isEmpty()) {
                return;
            }
            
            // Criar c√≥pia do buffer para evitar problemas de concorr√™ncia
            Map<Long, ClusterHealthMetrics> metricsToSave = new ConcurrentHashMap<>(metricsBuffer);
            
            // Limpar buffer ap√≥s copiar
            metricsBuffer.clear();
            
            // Salvar todas as m√©tricas em batch
            if (!metricsToSave.isEmpty()) {
                metricsRepository.saveAll(metricsToSave.values());
                
                boolean isDebugMode = "true".equalsIgnoreCase(System.getenv("DEBUG")) || 
                                     "true".equalsIgnoreCase(System.getProperty("debug"));
                if (isDebugMode) {
                    System.out.println("üíæ M√©tricas salvas no banco: " + metricsToSave.size() + " clusters");
                }
            }
            
        } catch (Exception e) {
            // N√£o quebrar o scheduler se houver erro
            if ("true".equalsIgnoreCase(System.getenv("DEBUG")) || 
                "true".equalsIgnoreCase(System.getProperty("debug"))) {
                System.err.println("Erro ao salvar m√©tricas no banco: " + e.getMessage());
            }
        }
    }
    
    /**
     * Obt√©m lista de clusters rodando usando cache (evita queries repetidas)
     * Usa lock para evitar m√∫ltiplas atualiza√ß√µes simult√¢neas
     */
    private List<Cluster> getCachedRunningClusters() {
        long now = System.currentTimeMillis();
        
        // Verificar cache v√°lido
        if (!cachedRunningClusters.isEmpty() && (now - lastClusterCacheUpdate) < CLUSTER_CACHE_TTL_MS) {
            return cachedRunningClusters;
        }
        
        // Cache expirado - atualizar apenas se n√£o estiver sendo atualizado por outra thread
        if (!isUpdatingClusterCache && (now - lastClusterCacheUpdate) >= CLUSTER_CACHE_TTL_MS) {
            synchronized (this) {
                // Double-check: verificar novamente dentro do lock
                if (!isUpdatingClusterCache && (now - lastClusterCacheUpdate) >= CLUSTER_CACHE_TTL_MS) {
                    isUpdatingClusterCache = true;
                    try {
                        // Usar query otimizada que carrega user em uma √∫nica query (join fetch)
                        // Isso evita N+1 queries de users
                        List<Cluster> allClusters = clusterRepository.findAllWithUser();
                        System.out.println("üîç Verificando " + allClusters.size() + " cluster(s) para coleta de m√©tricas...");
                        
                        cachedRunningClusters = allClusters.stream()
                            .filter(cluster -> {
                                // Verificar se cluster tem container realmente rodando
                                // SEMPRE priorizar usar o containerId se dispon√≠vel (mais preciso e r√°pido)
                                try {
                                    String containerIdentifier = cluster.getContainerId();
                                    boolean usingContainerId = (containerIdentifier != null && !containerIdentifier.isEmpty());
                                    
                                    // Se n√£o tem containerId, buscar pelo nome sanitizado
                                    if (!usingContainerId) {
                                        String sanitizedName = cluster.getSanitizedContainerName();
                                        if (sanitizedName != null && !sanitizedName.isEmpty()) {
                                            dockerService.clearContainerCache(sanitizedName);
                                            containerIdentifier = dockerService.getContainerId(sanitizedName);
                                            if (containerIdentifier != null && !containerIdentifier.isEmpty()) {
                                                // Encontrou pelo nome - atualizar containerId no cluster (em mem√≥ria)
                                                cluster.setContainerId(containerIdentifier);
                                                usingContainerId = true;
                                            } else {
                                                // N√£o encontrou pelo nome, tentar usar o nome diretamente
                                                containerIdentifier = sanitizedName;
                                            }
                                        }
                                    }
                                    
                                    if (containerIdentifier == null || containerIdentifier.isEmpty()) {
                                        return false;
                                    }
                                    
                                    // Verificar status real do container usando o identificador
                                    String result = dockerService.inspectContainer(containerIdentifier, "{{.State.Status}}");
                                    
                                    // Se o containerId n√£o funcionou, tentar buscar pelo nome sanitizado
                                    if ((result == null || result.isEmpty() || 
                                         result.contains("No such container") || result.contains("not found")) 
                                        && usingContainerId) {
                                        // ContainerId est√° desatualizado - tentar buscar pelo nome
                                        String sanitizedName = cluster.getSanitizedContainerName();
                                        if (sanitizedName != null && !sanitizedName.isEmpty()) {
                                            dockerService.clearContainerCache(sanitizedName);
                                            String foundId = dockerService.getContainerId(sanitizedName);
                                            if (foundId != null && !foundId.isEmpty()) {
                                                // Encontrou pelo nome - atualizar containerId
                                                containerIdentifier = foundId;
                                                cluster.setContainerId(foundId);
                                                result = dockerService.inspectContainer(containerIdentifier, "{{.State.Status}}");
                                            }
                                        }
                                    }
                                    
                                    if (result == null || result.isEmpty()) {
                                        return false;
                                    }
                                    
                                    // Se o comando foi executado com sucesso (c√≥digo 0), extrair o status
                                    if (result.contains("Process exited with code: 0")) {
                                        // Extrair status
                                        String status = result.replace("Process exited with code: 0", "").trim().toLowerCase();
                                        return status.contains("running");
                                    } else {
                                        // Se o comando falhou, verificar se √© porque o container n√£o existe
                                        if (result.contains("No such container") || result.contains("not found")) {
                                            return false;
                                        }
                                        // Outro erro - tentar usar o resultado como est√°
                                        return result.toLowerCase().contains("running");
                                    }
                                } catch (Exception e) {
                                    // Em caso de erro, n√£o incluir o cluster (evita coletas de containers inexistentes)
                                    return false;
                                }
                            })
                            .collect(Collectors.toList());
                        
                        // Atualizar containerIds no banco para clusters que foram encontrados
                        // Fazer isso de forma ass√≠ncrona para n√£o bloquear o cache
                        if (!cachedRunningClusters.isEmpty()) {
                            CompletableFuture.runAsync(() -> {
                                try {
                                    clusterRepository.saveAll(cachedRunningClusters);
                                } catch (Exception e) {
                                    // N√£o quebrar se falhar ao salvar
                                    System.err.println("‚ö†Ô∏è Erro ao atualizar containerIds: " + e.getMessage());
                                }
                            });
                        }
                        
                        System.out.println("‚úÖ Total de " + cachedRunningClusters.size() + " cluster(s) rodando encontrado(s) para coleta de m√©tricas");
                        lastClusterCacheUpdate = System.currentTimeMillis();
                    } catch (Exception e) {
                        // Se falhar, manter cache existente
                    } finally {
                        isUpdatingClusterCache = false;
                    }
                }
            }
        }
        
        // Retornar cache (mesmo que expirado, √© melhor que fazer query)
        return cachedRunningClusters;
    }
    
    /**
     * Limpa cache de √∫ltima coleta (√∫til para testes ou reset)
     */
    public void clearCollectionCache() {
        lastCollectionTime.clear();
        metricsBuffer.clear();
        cachedRunningClusters.clear();
        lastClusterCacheUpdate = 0;
    }
}

