package com.seveninterprise.clusterforge.services;

import com.seveninterprise.clusterforge.model.Cluster;
import com.seveninterprise.clusterforge.model.ClusterHealthMetrics;
import com.seveninterprise.clusterforge.repository.ClusterRepository;
import com.seveninterprise.clusterforge.repositories.ClusterHealthMetricsRepository;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.dao.DataIntegrityViolationException;
import org.springframework.scheduling.annotation.Scheduled;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;

import java.util.ArrayList;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Set;
import java.util.concurrent.CompletableFuture;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.stream.Collectors;

/**
 * Servi√ßo dedicado para coletar m√©tricas em alta frequ√™ncia (20 pacotes/segundo)
 * 
 * Este servi√ßo coleta m√©tricas do Docker de forma ass√≠ncrona e otimizada,
 * permitindo atualiza√ß√µes em tempo real sem bloquear o sistema principal.
 */
@Service
public class HighFrequencyMetricsCollector {
    
    private static final Logger log = LoggerFactory.getLogger(HighFrequencyMetricsCollector.class);
    
    private final ClusterRepository clusterRepository;
    private final ClusterHealthService clusterHealthService;
    private final MetricsWebSocketService metricsWebSocketService;
    private final ClusterHealthMetricsRepository metricsRepository;
    private final DockerService dockerService;
    
    // Executor para coletar m√©tricas em paralelo
    private final ExecutorService metricsCollectorExecutor;
    
    // Cache de √∫ltima coleta por cluster (para evitar coletas muito frequentes do mesmo cluster)
    private final Map<Long, Long> lastCollectionTime = new ConcurrentHashMap<>();
    // Intervalo m√≠nimo entre coletas do mesmo cluster (ajustado para 200ms para evitar sobrecarga)
    private static final long MIN_COLLECTION_INTERVAL_MS = 200; // M√≠nimo de 200ms entre coletas do mesmo cluster
    
    // POOL DE M√âTRICAS: Buffer de m√©tricas para salvar no banco
    // Armazena a √∫ltima m√©trica coletada de cada cluster
    private final Map<Long, ClusterHealthMetrics> metricsBuffer = new ConcurrentHashMap<>();
    
    // Controle de tempo: √∫ltima vez que salvamos m√©trica de cada cluster
    // Permite salvar apenas 1 m√©trica por cluster a cada minuto
    private final Map<Long, Long> lastSavedTime = new ConcurrentHashMap<>();
    private static final long MIN_SAVE_INTERVAL_MS = 60000; // 1 minuto = 60 segundos
    
    // Limite m√°ximo do buffer para evitar memory leaks (1000 clusters = limite razo√°vel)
    private static final int MAX_BUFFER_SIZE = 1000;
    
    // Pool de m√©tricas que falharam ao salvar (para retry)
    private final Map<Long, ClusterHealthMetrics> failedMetricsBuffer = new ConcurrentHashMap<>();
    private static final int MAX_FAILED_BUFFER_SIZE = 100; // Limite para evitar crescimento infinito
    
    // Cache de clusters ativos (atualizado a cada 5 segundos para reduzir queries)
    private volatile List<Cluster> cachedRunningClusters = new java.util.ArrayList<>();
    private volatile long lastClusterCacheUpdate = 0;
    private static final long CLUSTER_CACHE_TTL_MS = 5000; // Cache v√°lido por 5 segundos
    private volatile boolean isUpdatingClusterCache = false; // Lock para evitar m√∫ltiplas atualiza√ß√µes simult√¢neas
    
    // Set de clusters que est√£o sendo deletados (para evitar race condition)
    private final java.util.Set<Long> clustersBeingDeleted = ConcurrentHashMap.newKeySet();
    
    // Cache de IDs de clusters v√°lidos (para valida√ß√£o r√°pida antes de salvar)
    private volatile Set<Long> validClusterIds = new HashSet<>();
    private volatile long lastValidClusterIdsUpdate = 0;
    private static final long VALID_CLUSTER_IDS_CACHE_TTL_MS = 30000; // 30 segundos
    
    @Autowired
    public HighFrequencyMetricsCollector(
            ClusterRepository clusterRepository,
            ClusterHealthService clusterHealthService,
            MetricsWebSocketService metricsWebSocketService,
            ClusterHealthMetricsRepository metricsRepository,
            DockerService dockerService) {
        this.clusterRepository = clusterRepository;
        this.clusterHealthService = clusterHealthService;
        this.metricsWebSocketService = metricsWebSocketService;
        this.metricsRepository = metricsRepository;
        this.dockerService = dockerService;
        
        // Thread pool otimizado para coleta r√°pida de m√©tricas
        // Usa n√∫mero de cores dispon√≠veis para paralelismo
        int threadPoolSize = Math.max(4, Runtime.getRuntime().availableProcessors());
        this.metricsCollectorExecutor = Executors.newFixedThreadPool(threadPoolSize);
    }
    
    /**
     * Scheduler para coletar m√©tricas em alta frequ√™ncia (a cada 100ms = 10x/segundo)
     * Coleta apenas m√©tricas de recursos (CPU, RAM, Disk, Network) de forma r√°pida
     * sem fazer health checks completos.
     * 
     * Nota: 100ms √© um bom equil√≠brio entre frequ√™ncia e performance.
     * O WebSocket pode enviar at√© 20x/segundo, mas coletar do Docker a cada 50ms
     * pode ser muito pesado. 100ms (10x/segundo) √© mais realista.
     */
    @Scheduled(fixedRate = 100) // 100ms = 10 vezes por segundo (mais realista para coleta do Docker)
    public void collectMetricsHighFrequency() {
        try {
            // Usar cache de clusters para evitar queries a cada 100ms
            List<Cluster> runningClusters = getCachedRunningClusters();
            
            // Log apenas a cada 5 segundos para n√£o poluir logs
            long now = System.currentTimeMillis();
            boolean shouldLog = (now - lastClusterCacheUpdate) < 100; // Log apenas logo ap√≥s atualiza√ß√£o do cache
            
            if (runningClusters.isEmpty()) {
                if (shouldLog) {
                    System.out.println("‚ö†Ô∏è Nenhum cluster rodando encontrado para coletar m√©tricas");
                }
                return;
            }
            
            if (shouldLog && runningClusters.size() > 0) {
                System.out.println("üìä Coletando m√©tricas para " + runningClusters.size() + " cluster(s) rodando");
            }
            
            // Coletar m√©tricas de todos os clusters em paralelo
            // N√£o aguardar todas as coletas - deixar rodar em background
            // Isso permite que o scheduler continue rodando a cada 100ms
            // IMPORTANTE: Filtrar clusters que est√£o sendo deletados para evitar race condition
            runningClusters.stream()
                .filter(cluster -> !clustersBeingDeleted.contains(cluster.getId()))
                .forEach(cluster -> {
                CompletableFuture.runAsync(() -> {
                    try {
                        collectMetricsForCluster(cluster);
                    } catch (Exception e) {
                        // N√£o logar erros para n√£o poluir logs em alta frequ√™ncia
                        // Apenas em modo debug
                        if ("true".equalsIgnoreCase(System.getenv("DEBUG")) || 
                            "true".equalsIgnoreCase(System.getProperty("debug"))) {
                            System.err.println("Erro ao coletar m√©tricas para cluster " + cluster.getId() + ": " + e.getMessage());
                        }
                    }
                }, metricsCollectorExecutor);
            });
            
        } catch (Exception e) {
            // N√£o quebrar o scheduler se houver erro
            if ("true".equalsIgnoreCase(System.getenv("DEBUG")) || 
                "true".equalsIgnoreCase(System.getProperty("debug"))) {
                System.err.println("Erro no scheduler de coleta de m√©tricas: " + e.getMessage());
            }
        }
    }
    
    /**
     * Coleta m√©tricas para um cluster espec√≠fico diretamente do Docker
     * e envia via WebSocket sem passar pelo banco de dados
     */
    private void collectMetricsForCluster(Cluster cluster) {
        // Verificar se o cluster est√° sendo deletado (double-check)
        if (clustersBeingDeleted.contains(cluster.getId())) {
            return; // N√£o coletar m√©tricas para clusters sendo deletados
        }
        
        // Throttling por cluster: evitar coletas muito frequentes do mesmo cluster
        long now = System.currentTimeMillis();
        Long lastCollection = lastCollectionTime.get(cluster.getId());
        if (lastCollection != null && (now - lastCollection) < MIN_COLLECTION_INTERVAL_MS) {
            return; // Ainda n√£o passou o intervalo m√≠nimo
        }
        
        lastCollectionTime.put(cluster.getId(), now);
        
        try {
            // Coletar m√©tricas diretamente do Docker
            // Pular m√©tricas adicionais (docker inspect) e usar quiet mode para n√£o poluir logs
            ClusterHealthMetrics metrics = clusterHealthService.collectResourceMetrics(cluster, true, true);
            
            if (metrics != null) {
                // Enviar diretamente via WebSocket (sem salvar no banco imediatamente)
                metricsWebSocketService.sendMetricsDirectly(cluster, metrics);
                
                // Armazenar no POOL de m√©tricas para salvar no banco a cada 10 segundos
                // Verificar limite do buffer para evitar memory leaks
                if (metricsBuffer.size() < MAX_BUFFER_SIZE) {
                metricsBuffer.put(cluster.getId(), metrics);
                } else {
                    log.warn("‚ö†Ô∏è [METRICS POOL] Buffer de m√©tricas atingiu limite m√°ximo ({}). Ignorando m√©trica do cluster {}", 
                        MAX_BUFFER_SIZE, cluster.getId());
                }
            }
        } catch (Exception e) {
            // Ignorar erros silenciosamente para n√£o quebrar o scheduler
            // Em modo debug, logar
            if ("true".equalsIgnoreCase(System.getenv("DEBUG")) || 
                "true".equalsIgnoreCase(System.getProperty("debug"))) {
                System.err.println("Erro ao coletar m√©tricas para cluster " + cluster.getId() + ": " + e.getMessage());
            }
        }
    }
    
    /**
     * Scheduler para salvar m√©tricas no banco a cada 10 segundos
     * Salva apenas 1 m√©trica por cluster a cada minuto (60 segundos)
     * 
     * Sistema de POOL: M√©tricas s√£o coletadas e armazenadas em cache,
     * depois inseridas em batch no banco de dados com valida√ß√µes.
     * 
     * IMPORTANTE: Cada cluster ter√° apenas 1 m√©trica salva por minuto,
     * mesmo que sejam coletadas centenas de m√©tricas durante esse per√≠odo.
     * Isso reduz drasticamente a carga no banco de dados e evita race conditions.
     */
    @Scheduled(fixedRate = 10000) // Verifica a cada 10 segundos
    @Transactional(timeout = 15) // Timeout de 15 segundos para batch save
    public void saveMetricsToDatabase() {
        long startTime = System.currentTimeMillis();
        int totalMetrics = 0;
        int savedMetrics = 0;
        int failedMetrics = 0;
        int skippedMetrics = 0;
        
        try {
            // Atualizar cache de IDs v√°lidos de clusters
            updateValidClusterIdsCache();
            
            long now = System.currentTimeMillis();
            
            // Filtrar m√©tricas que podem ser salvas (apenas 1 por cluster a cada minuto)
            Map<Long, ClusterHealthMetrics> metricsToSave = new ConcurrentHashMap<>();
            
            for (Map.Entry<Long, ClusterHealthMetrics> entry : metricsBuffer.entrySet()) {
                Long clusterId = entry.getKey();
                ClusterHealthMetrics metrics = entry.getValue();
                
                // 1. Verificar se cluster est√° sendo deletado
                if (clustersBeingDeleted.contains(clusterId)) {
                    skippedMetrics++;
                    // Remover do buffer se est√° sendo deletado
                    metricsBuffer.remove(clusterId);
                    lastSavedTime.remove(clusterId);
                    log.debug("‚è≠Ô∏è [METRICS POOL] Pulando m√©trica do cluster {} (sendo deletado)", clusterId);
                    continue;
                }
                
                // 2. Verificar se cluster ainda existe no banco
                if (!isValidCluster(clusterId)) {
                    skippedMetrics++;
                    // Remover do buffer se cluster n√£o existe mais
                    metricsBuffer.remove(clusterId);
                    lastSavedTime.remove(clusterId);
                    log.debug("‚è≠Ô∏è [METRICS POOL] Pulando m√©trica do cluster {} (n√£o existe mais)", clusterId);
                    continue;
                }
                
                // 3. Validar integridade dos dados da m√©trica
                if (!isValidMetrics(metrics)) {
                    skippedMetrics++;
                    metricsBuffer.remove(clusterId);
                    log.warn("‚ö†Ô∏è [METRICS POOL] M√©trica inv√°lida para cluster {}: {}", clusterId, metrics);
                    continue;
                }
                
                // 4. VERIFICAR SE J√Å PASSOU 1 MINUTO desde a √∫ltima vez que salvamos m√©trica deste cluster
                Long lastSaved = lastSavedTime.get(clusterId);
                if (lastSaved != null && (now - lastSaved) < MIN_SAVE_INTERVAL_MS) {
                    // Ainda n√£o passou 1 minuto - manter no buffer para pr√≥xima verifica√ß√£o
                    skippedMetrics++;
                    continue;
                }
                
                // Passou 1 minuto ou nunca salvamos - adicionar √† lista para salvar
                metricsToSave.put(clusterId, metrics);
            }
            
            totalMetrics = metricsBuffer.size();
            
            if (metricsToSave.isEmpty()) {
                // Tentar salvar m√©tricas que falharam anteriormente
                retryFailedMetrics();
                return;
            }
            
            // Remover m√©tricas que ser√£o salvas do buffer (mas manter as outras para pr√≥xima verifica√ß√£o)
            for (Long clusterId : metricsToSave.keySet()) {
                metricsBuffer.remove(clusterId);
            }
            
            // Converter para lista para valida√ß√£o final
            List<ClusterHealthMetrics> validatedMetrics = new ArrayList<>(metricsToSave.values());
            
            // Salvar m√©tricas validadas em batch
            if (!validatedMetrics.isEmpty()) {
                try {
                    metricsRepository.saveAll(validatedMetrics);
                    savedMetrics = validatedMetrics.size();
                    
                    // Atualizar timestamp de √∫ltima salvamento para cada cluster salvo
                    for (ClusterHealthMetrics metric : validatedMetrics) {
                        Long clusterId = metric.getCluster().getId();
                        lastSavedTime.put(clusterId, now);
                    }
                    
                    log.info("üíæ [METRICS POOL] {} m√©trica(s) salva(s) no banco ({} no buffer, {} aguardando pr√≥ximo minuto, {} pulada(s))", 
                        savedMetrics, totalMetrics, skippedMetrics, failedMetrics);
                } catch (DataIntegrityViolationException e) {
                    // Erro de constraint - pode ser foreign key ou unique
                    log.error("‚ùå [METRICS POOL] Erro de integridade ao salvar m√©tricas: {}", e.getMessage());
                    // Tentar salvar individualmente para identificar qual falhou
                    saveMetricsIndividually(validatedMetrics, now);
                } catch (Exception e) {
                    log.error("‚ùå [METRICS POOL] Erro ao salvar m√©tricas em batch: {}", e.getMessage(), e);
                    // Tentar salvar individualmente
                    saveMetricsIndividually(validatedMetrics, now);
                }
            }
            
            // Tentar salvar m√©tricas que falharam anteriormente
            retryFailedMetrics();
            
            long duration = System.currentTimeMillis() - startTime;
            if (duration > 1000) {
                log.warn("‚ö†Ô∏è [METRICS POOL] Salvamento de m√©tricas demorou {}ms (acima do esperado)", duration);
            }
            
        } catch (Exception e) {
            log.error("‚ùå [METRICS POOL] Erro inesperado ao salvar m√©tricas no banco: {}", e.getMessage(), e);
        }
    }
    
    /**
     * Salva m√©tricas individualmente para identificar quais falharam
     */
    private void saveMetricsIndividually(List<ClusterHealthMetrics> metrics, long now) {
        int saved = 0;
        int failed = 0;
        
        for (ClusterHealthMetrics metric : metrics) {
            Long clusterId = metric.getCluster().getId();
            try {
                // Verificar novamente se cluster ainda existe antes de salvar
                if (!isValidCluster(clusterId)) {
                    failed++;
                    lastSavedTime.remove(clusterId);
                    continue;
                }
                
                metricsRepository.save(metric);
                saved++;
                // Atualizar timestamp de √∫ltima salvamento
                lastSavedTime.put(clusterId, now);
            } catch (DataIntegrityViolationException e) {
                // Cluster foi deletado ou constraint violada - adicionar ao buffer de falhas
                failed++;
                lastSavedTime.remove(clusterId);
                if (failedMetricsBuffer.size() < MAX_FAILED_BUFFER_SIZE) {
                    failedMetricsBuffer.put(clusterId, metric);
                }
                log.debug("‚ö†Ô∏è [METRICS POOL] Falha ao salvar m√©trica do cluster {}: {}", 
                    clusterId, e.getMessage());
            } catch (Exception e) {
                failed++;
                lastSavedTime.remove(clusterId);
                log.warn("‚ö†Ô∏è [METRICS POOL] Erro ao salvar m√©trica do cluster {}: {}", 
                    clusterId, e.getMessage());
            }
        }
        
        if (saved > 0) {
            log.info("üíæ [METRICS POOL] {} m√©trica(s) salva(s) individualmente ({} falha(s))", saved, failed);
        }
    }
    
    /**
     * Tenta salvar novamente m√©tricas que falharam anteriormente
     */
    private void retryFailedMetrics() {
        if (failedMetricsBuffer.isEmpty()) {
            return;
        }
        
        Map<Long, ClusterHealthMetrics> toRetry = new ConcurrentHashMap<>(failedMetricsBuffer);
        failedMetricsBuffer.clear();
        
        int retried = 0;
        int stillFailed = 0;
        
        for (Map.Entry<Long, ClusterHealthMetrics> entry : toRetry.entrySet()) {
            Long clusterId = entry.getKey();
            ClusterHealthMetrics metrics = entry.getValue();
            
            // Verificar se cluster ainda existe
            if (!isValidCluster(clusterId) || clustersBeingDeleted.contains(clusterId)) {
                stillFailed++;
                continue;
            }
            
            try {
                metricsRepository.save(metrics);
                retried++;
            } catch (Exception e) {
                stillFailed++;
                // Se ainda falhar, manter no buffer (mas limitar tamanho)
                if (failedMetricsBuffer.size() < MAX_FAILED_BUFFER_SIZE) {
                    failedMetricsBuffer.put(clusterId, metrics);
                }
            }
        }
        
        if (retried > 0) {
            log.info("üîÑ [METRICS POOL] {} m√©trica(s) reenviada(s) com sucesso ({} ainda falhando)", retried, stillFailed);
        }
    }
    
    /**
     * Valida se uma m√©trica tem dados v√°lidos
     */
    private boolean isValidMetrics(ClusterHealthMetrics metrics) {
        if (metrics == null) {
            return false;
        }
        
        if (metrics.getCluster() == null || metrics.getCluster().getId() == null) {
            return false;
        }
        
        if (metrics.getTimestamp() == null) {
            return false;
        }
        
        return true;
    }
    
    /**
     * Verifica se um cluster ainda existe no banco de dados
     */
    private boolean isValidCluster(Long clusterId) {
        if (clusterId == null) {
            return false;
        }
        
        // Verificar cache de IDs v√°lidos
        if (validClusterIds.contains(clusterId)) {
            return true;
        }
        
        // Se n√£o est√° no cache, verificar no banco (mais lento)
        boolean exists = clusterRepository.existsById(clusterId);
        if (exists) {
            validClusterIds.add(clusterId);
        }
        
        return exists;
    }
    
    /**
     * Atualiza cache de IDs v√°lidos de clusters
     */
    private void updateValidClusterIdsCache() {
        long now = System.currentTimeMillis();
        
        if ((now - lastValidClusterIdsUpdate) < VALID_CLUSTER_IDS_CACHE_TTL_MS) {
            return; // Cache ainda v√°lido
        }
        
        try {
            // Buscar todos os IDs de clusters existentes
            List<Long> allClusterIds = clusterRepository.findAllIds();
            validClusterIds = new HashSet<>(allClusterIds);
            lastValidClusterIdsUpdate = now;
            log.debug("üîÑ [METRICS POOL] Cache de IDs v√°lidos atualizado: {} clusters", validClusterIds.size());
        } catch (Exception e) {
            log.warn("‚ö†Ô∏è [METRICS POOL] Erro ao atualizar cache de IDs v√°lidos: {}", e.getMessage());
        }
    }
    
    /**
     * Obt√©m lista de clusters rodando usando cache (evita queries repetidas)
     * Usa lock para evitar m√∫ltiplas atualiza√ß√µes simult√¢neas
     */
    private List<Cluster> getCachedRunningClusters() {
        long now = System.currentTimeMillis();
        
        // Verificar cache v√°lido
        if (!cachedRunningClusters.isEmpty() && (now - lastClusterCacheUpdate) < CLUSTER_CACHE_TTL_MS) {
            return cachedRunningClusters;
        }
        
        // Cache expirado - atualizar apenas se n√£o estiver sendo atualizado por outra thread
        if (!isUpdatingClusterCache && (now - lastClusterCacheUpdate) >= CLUSTER_CACHE_TTL_MS) {
            synchronized (this) {
                // Double-check: verificar novamente dentro do lock
                if (!isUpdatingClusterCache && (now - lastClusterCacheUpdate) >= CLUSTER_CACHE_TTL_MS) {
                    isUpdatingClusterCache = true;
                    try {
                        // Usar query otimizada que carrega user em uma √∫nica query (join fetch)
                        // Isso evita N+1 queries de users
                        List<Cluster> allClusters = clusterRepository.findAllWithUser();
                        System.out.println("üîç Verificando " + allClusters.size() + " cluster(s) para coleta de m√©tricas...");
                        
                        cachedRunningClusters = allClusters.stream()
                            .filter(cluster -> {
                                // Verificar se cluster tem container realmente rodando
                                // SEMPRE priorizar usar o containerId se dispon√≠vel (mais preciso e r√°pido)
                                try {
                                    String containerIdentifier = cluster.getContainerId();
                                    boolean usingContainerId = (containerIdentifier != null && !containerIdentifier.isEmpty());
                                    
                                    // Se n√£o tem containerId, buscar pelo nome sanitizado
                                    if (!usingContainerId) {
                                        String sanitizedName = cluster.getSanitizedContainerName();
                                        if (sanitizedName != null && !sanitizedName.isEmpty()) {
                                            dockerService.clearContainerCache(sanitizedName);
                                            containerIdentifier = dockerService.getContainerId(sanitizedName);
                                            if (containerIdentifier != null && !containerIdentifier.isEmpty()) {
                                                // Encontrou pelo nome - atualizar containerId no cluster (em mem√≥ria)
                                                cluster.setContainerId(containerIdentifier);
                                                usingContainerId = true;
                                            } else {
                                                // N√£o encontrou pelo nome, tentar usar o nome diretamente
                                                containerIdentifier = sanitizedName;
                                            }
                                        }
                                    }
                                    
                                    if (containerIdentifier == null || containerIdentifier.isEmpty()) {
                                        return false;
                                    }
                                    
                                    // Verificar status real do container usando o identificador
                                    String result = dockerService.inspectContainer(containerIdentifier, "{{.State.Status}}");
                                    
                                    // Se o containerId n√£o funcionou, tentar buscar pelo nome sanitizado
                                    if ((result == null || result.isEmpty() || 
                                         result.contains("No such container") || result.contains("not found")) 
                                        && usingContainerId) {
                                        // ContainerId est√° desatualizado - tentar buscar pelo nome
                                        String sanitizedName = cluster.getSanitizedContainerName();
                                        if (sanitizedName != null && !sanitizedName.isEmpty()) {
                                            dockerService.clearContainerCache(sanitizedName);
                                            String foundId = dockerService.getContainerId(sanitizedName);
                                            if (foundId != null && !foundId.isEmpty()) {
                                                // Encontrou pelo nome - atualizar containerId
                                                containerIdentifier = foundId;
                                                cluster.setContainerId(foundId);
                                                result = dockerService.inspectContainer(containerIdentifier, "{{.State.Status}}");
                                            }
                                        }
                                    }
                                    
                                    if (result == null || result.isEmpty()) {
                                        return false;
                                    }
                                    
                                    // Se o comando foi executado com sucesso (c√≥digo 0), extrair o status
                                    if (result.contains("Process exited with code: 0")) {
                                        // Extrair status
                                        String status = result.replace("Process exited with code: 0", "").trim().toLowerCase();
                                        return status.contains("running");
                                    } else {
                                        // Se o comando falhou, verificar se √© porque o container n√£o existe
                                        if (result.contains("No such container") || result.contains("not found")) {
                                            return false;
                                        }
                                        // Outro erro - tentar usar o resultado como est√°
                                        return result.toLowerCase().contains("running");
                                    }
                                } catch (Exception e) {
                                    // Em caso de erro, n√£o incluir o cluster (evita coletas de containers inexistentes)
                                    return false;
                                }
                            })
                            .collect(Collectors.toList());
                        
                        // Atualizar containerIds no banco para clusters que foram encontrados
                        // Fazer isso de forma ass√≠ncrona para n√£o bloquear o cache
                        if (!cachedRunningClusters.isEmpty()) {
                            CompletableFuture.runAsync(() -> {
                                try {
                                    clusterRepository.saveAll(cachedRunningClusters);
                                } catch (Exception e) {
                                    // N√£o quebrar se falhar ao salvar
                                    System.err.println("‚ö†Ô∏è Erro ao atualizar containerIds: " + e.getMessage());
                                }
                            });
                        }
                        
                        System.out.println("‚úÖ Total de " + cachedRunningClusters.size() + " cluster(s) rodando encontrado(s) para coleta de m√©tricas");
                        lastClusterCacheUpdate = System.currentTimeMillis();
                    } catch (Exception e) {
                        // Se falhar, manter cache existente
                    } finally {
                        isUpdatingClusterCache = false;
                    }
                }
            }
        }
        
        // Retornar cache (mesmo que expirado, √© melhor que fazer query)
        return cachedRunningClusters;
    }
    
    /**
     * Marca um cluster como sendo deletado para evitar coleta de m√©tricas durante a dele√ß√£o
     * Isso previne race condition onde m√©tricas s√£o inseridas ap√≥s limpeza mas antes da dele√ß√£o
     */
    public void markClusterAsDeleting(Long clusterId) {
        clustersBeingDeleted.add(clusterId);
        // Remover do buffer de m√©tricas para evitar que seja salvo
        metricsBuffer.remove(clusterId);
        // Remover do cache de √∫ltima coleta
        lastCollectionTime.remove(clusterId);
    }
    
    /**
     * Remove marca√ß√£o de cluster sendo deletado (ap√≥s dele√ß√£o conclu√≠da ou cancelada)
     */
    public void unmarkClusterAsDeleting(Long clusterId) {
        clustersBeingDeleted.remove(clusterId);
    }
    
    /**
     * Limpa cache de √∫ltima coleta (√∫til para testes ou reset)
     */
    public void clearCollectionCache() {
        lastCollectionTime.clear();
        metricsBuffer.clear();
        lastSavedTime.clear();
        cachedRunningClusters.clear();
        lastClusterCacheUpdate = 0;
    }
}

